{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN assignment**(Do read the note at the end)"
      ],
      "metadata": {
        "id": "4kESsOo4IUhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description: Here we are going to use CNN to classify images of elephants,tigers,cheetah's and crocodiles. Basically multiclass classificiation using CNN."
      ],
      "metadata": {
        "id": "deWESXcqELuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.1** Import all required modules"
      ],
      "metadata": {
        "id": "-tI6CGxtJraE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ML_oQP0SJu-c"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.2** Load data using image_dataset_from_directory(https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)"
      ],
      "metadata": {
        "id": "PyPMlrh4H_h1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"C:\\Users\\Shraddha\\Downloads\\Machine_Learning\\Train\",\n",
        "    labels='inferred',\n",
        "    label_mode='int',\n",
        "    class_names=None,\n",
        "    color_mode='rgb',\n",
        "    batch_size=32,\n",
        "    image_size=(256, 256),\n",
        "    shuffle=True,\n",
        "    seed=None,\n",
        "    validation_split=0.2,\n",
        "    subset='both',\n",
        "    interpolation='bilinear',\n",
        "    follow_links=False,\n",
        "    crop_to_aspect_ratio=False,\n",
        "    pad_to_aspect_ratio=False,\n",
        "    data_format=None,\n",
        "    verbose=True\n",
        ")#Your code here"
      ],
      "metadata": {
        "id": "mmJtCqmeWcH-",
        "outputId": "67263b84-8d33-437e-af14-62f08077592a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-2-5582a8261857>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-5582a8261857>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \"C:\\Users\\Shraddha\\Downloads\\Machine_Learning\\Train\",\u001b[0m\n\u001b[0m                                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Since data object is not iterable,we will create a nummpy iterator for data.\n",
        "*   Then use batch to iterate through our data\n",
        "\n"
      ],
      "metadata": {
        "id": "0Lz_opzEIkxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator=data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "YdeyCp3vIZJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch=data_iterator.next()"
      ],
      "metadata": {
        "id": "M0BrVzJgI0Ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code and batch code 2-3 times to visualise the labels given to different animals."
      ],
      "metadata": {
        "id": "BFYhZBK8I7OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(ncols=4,figsize=(20,20))\n",
        "for idx,img in enumerate(batch[0][:4]):\n",
        "  ax[idx].imshow(img.astype(int))\n",
        "  ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "0U_gObC_WfD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.3** Map the data such that all pixel values lie between 0 and 1 using the **lambda function**"
      ],
      "metadata": {
        "id": "dlFxTOYEJHh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.map(#Your code here)"
      ],
      "metadata": {
        "id": "ZQLDb494JQMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.4** Split the data into train set and test set(and validation set if needed) using **data.take**(https://www.geeksforgeeks.org/tensorflow-js-tf-data-dataset-class-take-method/) and **data.skip**(https://www.geeksforgeeks.org/tensorflow-js-tf-data-dataset-skip-method/)"
      ],
      "metadata": {
        "id": "ngGqgBHVKIm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Your code here\n"
      ],
      "metadata": {
        "id": "rm8j2Jl6KXJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the model**"
      ],
      "metadata": {
        "id": "6znfO5DkJU0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.5** Write code to create CNN model including fully connected layers with softmax as final layer."
      ],
      "metadata": {
        "id": "BFS_ikF4JyKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=#Your code here"
      ],
      "metadata": {
        "id": "H9OPh20BKDnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.6** Compile your model"
      ],
      "metadata": {
        "id": "qdegbXaZKdPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(#Your code here)"
      ],
      "metadata": {
        "id": "fz2VU4OSKmwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.7** Fit your model with train set and make sure to keep **less epochs**(10-15) as the dataset size is very large."
      ],
      "metadata": {
        "id": "zfZijguvKpxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(#Your code here)"
      ],
      "metadata": {
        "id": "gHBM-8LTC-qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q.8** Test your code with test set"
      ],
      "metadata": {
        "id": "3Cq6ZBwKLLC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss,accuracy=model.evaluate(#Your code here)"
      ],
      "metadata": {
        "id": "4Ryizmz1LRMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not change this code\n",
        "if accuracy>=0.85:\n",
        "  print(f\"Congratulations, CNN assignment complete!! Your accuracy is {accuracy}\")\n",
        "else:\n",
        "  print(f\"Try again, not enough accuracy! Your accuracy is {accuracy}\" )"
      ],
      "metadata": {
        "id": "_BkSZvLLLYF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: 1. Many of you will get very high train accuracy but low test accuracy. This is called overfitting, this can be solved by increasing the train set size. If your getting low accuracy for both train and test, modify your layers in the model.**\n",
        "\n",
        "**2.Do use T4GPU.Ideally your first epoch will take quite sometime and rest of the epochs will be faster but if all your epochs are taking a lot of time, try starting a new gpu session(open a new gmail account and open colab on that) because your free gpu might have exhausted itself.**\n",
        "\n",
        "**3.Other than that everything should be fine, happy learning!!**"
      ],
      "metadata": {
        "id": "y91gKo0wLox0"
      }
    }
  ]
}